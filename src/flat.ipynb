{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "306a1264-fea9-4302-af2f-3c531b8e64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9fe8a146-6f60-4360-a02b-f84c0118b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import datasets, neighbors, metrics, tree, svm, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "\n",
    "# Calculates the per-class accuracy given predicted and true output labels.\n",
    "def class_accs(y_pred, y_true):\n",
    "    acc0 = ((y_pred == y_true) & (y_true == 0)).sum() / (y_true == 0).sum()\n",
    "    acc1 = ((y_pred == y_true) & (y_true == 1)).sum() / (y_true == 1).sum()\n",
    "    return acc0, acc1\n",
    "\n",
    "# Prints a summary of performance metrics given predicted and true output labels. (source: pract3)\n",
    "def print_metrics(y_pred, y_true):\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "    f1 = metrics.f1_score(y_true, y_pred, average=None)\n",
    "    acc = metrics.accuracy_score(y_true, y_pred)\n",
    "    #acc0, acc1 = class_accs(y_pred, y_true)\n",
    "    print(f'\\tF1 = {f1}')\n",
    "    print(f'\\tAccuracy = {acc}')\n",
    "    #print(f'\\t\\tclass 0: {acc0}')\n",
    "    #print(f'\\t\\tclass 1: {acc1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87544c7d-07bd-4eb4-ae42-7ac52a4f9fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 8s, sys: 7.38 s, total: 4min 15s\n",
      "Wall time: 4min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load labels\n",
    "labels = pd.read_csv('../data/Lauren/Labels.csv')\n",
    "#labels.head() # to display the first 5 lines of loaded data\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('../data/Lauren/500_PBMC_3p_LT_Chromium_X_metrics_summary.csv') # takes about 5min\n",
    "\n",
    "# filter out Endothelial because barely any entries\n",
    "keep_indices = labels[\"Class\"].isin(['GABAergic', 'Glutamatergic', 'Non-Neuronal'])\n",
    "labels = labels[keep_indices]\n",
    "df = df[keep_indices]\n",
    "\n",
    "# remove names of cells\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "# only keep most specific classification \n",
    "labels = labels.drop(columns = [\"Class\", \"Subclass\"]).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "206c4e33-00ec-499c-93a9-613acf444408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Vip Arhgap36 Hmcn1', 'Lamp5 Lsp1', 'Lamp5 Lsp1', ...,\n",
       "       'Pvalb Gpr149 Islr', 'L5 PT VISp C1ql2 Cdh13', 'Sst Calb2 Pdlim5'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42395df1-7e17-4143-a6bb-61ec3331e6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd1d840d-5033-4035-b682-bf7238e5deb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting\n",
      "Start predicting\n",
      "Calculating metrics\n",
      "\tF1 = 0.6014040561622465\n",
      "\tAccuracy = 0.6014040561622465\n",
      "\t\tclass 0: nan\n",
      "\t\tclass 1: nan\n",
      "\u0007CPU times: user 10min 18s, sys: 13min 24s, total: 23min 43s\n",
      "Wall time: 3min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6146/4041633968.py:10: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  acc0 = ((y_pred == y_true) & (y_true == 0)).sum() / (y_true == 0).sum()\n",
      "/tmp/ipykernel_6146/4041633968.py:11: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  acc1 = ((y_pred == y_true) & (y_true == 1)).sum() / (y_true == 1).sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "size = df.shape[0]\n",
    "train_size = int(size/10)\n",
    "X_train = df[:train_size]\n",
    "y_train = labels[:train_size]\n",
    "X_test = df[train_size:2*train_size]\n",
    "y_test = labels[train_size:2*train_size]\n",
    "\n",
    "# duurt super lang\n",
    "#from sklearn import model_selection\n",
    "#print(model_selection.cross_validate(svm.SVC(kernel = 'linear'), X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24f076-bf90-4162-a6a1-6b904f0994bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1v1\n",
    "print(\"Start fitting\")\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Start predicting\")\n",
    "y_pred_clf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3af9a785-abbe-4eff-b54c-acb50333d582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting\n"
     ]
    }
   ],
   "source": [
    "# 1vRest\n",
    "print(\"Start fitting\")\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Start predicting\")\n",
    "y_pred_lin_clf = lin_clf.predict(X_test)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6feea2b-0a06-4c0e-835e-061f5a1c848d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Calculating metrics\")\n",
    "f1 = metrics.f1_score(y_test, y_pred, average=None)\n",
    "acc = metrics.accuracy_score(y_train, y_pred)\n",
    "\n",
    "unique_labels_df = pd.DataFrame(pd.Series(y_train).unique())\n",
    "f1_df = pd.DataFrame(f1)\n",
    "pd.concat([unique_labels_df, f1_df], axis=1, keys=['cluser', 'f1_per_cluster'])\n",
    "len(unique_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca4a68-8a20-4f49-8ae3-c63399756e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225e998-46a3-4623-aee7-741f70169206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
