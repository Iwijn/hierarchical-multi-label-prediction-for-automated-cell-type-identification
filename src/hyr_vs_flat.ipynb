{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a5db6e-459b-432a-950a-85f11269b765",
   "metadata": {},
   "source": [
    "# Comparing hyr classification with flat classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9cdf4c-0c12-4abf-8589-050a206b245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn import datasets, neighbors, metrics, tree, svm, preprocessing, model_selection, ensemble\n",
    "from sklearn.base import clone as sklearn_clone\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd34153-6622-4b85-b484-e33b8ad0b95e",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "This data has been preprocessed in pickle.ipynb and stored in .pkl files.\n",
    "This makes for much faster loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce685f8-b748-4af6-9e3a-3afb4a163eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 2.63 s, total: 2.63 s\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_pickle(\"../data/Lauren/bam_df.pkl\")\n",
    "labels = pd.read_pickle(\"../data/Lauren/bam_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b52c5b-59dc-4153-b557-2ff634a0c473",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d817d-3df8-43b1-9c44-d2d371eff4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_test, y_pred, f1_file_name=None):\n",
    "    unique_labels_df = pd.DataFrame(pd.Series(y_test).unique())\n",
    "    f1 = pd.DataFrame(metrics.f1_score(y_test, y_pred, average=None, labels = unique_labels_df[0]))\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"accuracy: {acc}\")\n",
    "    f1_micro = metrics.f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    f1_weighted = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"F1 micro-average: {f1_micro}\")\n",
    "    print(f\"F1 macro-average: {f1_macro}\")\n",
    "    print(f\"F1 weighted-average: {f1_weighted}\")\n",
    "    print()\n",
    "    \n",
    "    # seperate f1 score for each label\n",
    "    f1_labeled = pd.concat([unique_labels_df[0], f1[0]], axis=1, keys=['class', 'f1_per_class'])\n",
    "    # print(f1_labeled)\n",
    "    \n",
    "    # save seperate f1 scores\n",
    "    if f1_file_name is not None:\n",
    "        f1_labeled.to_csv(f1_file_name, index=False)\n",
    "    \n",
    "    return pd.DataFrame([[acc, f1_micro, f1_macro, f1_weighted]], columns=[\"accuracy\", \"F1 micro-average\", \"F1 macro-average\", \"F1 weighted-average\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03576bb0-08c2-4303-9728-f007c46b9021",
   "metadata": {},
   "source": [
    "## Flat classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c494023-1b4d-41cb-85c2-df04bb195d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a flat multi label classifier\n",
    "# df: X\n",
    "# labels: multiple columns, one of which will be y\n",
    "# class_column_name: the name of the column in labels that will be y\n",
    "def train_flat(clf, df, labels, class_column_name): # todo: give linear classifier as argument\n",
    "    # only keep the needed column\n",
    "    drop_columns = filter(lambda col: col != class_column_name , labels.columns)\n",
    "    labels = labels.drop(columns = drop_columns).values.ravel()\n",
    "     \n",
    "    X_train, y_train = df, labels\n",
    "    # copy the model, important for hierarchical\n",
    "    clf = sklearn_clone(clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c787b-b309-4434-85c5-35ce037cd59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat(clf, X, y, on_label=\"cluster\", folds=2, folds_random_state=1337):\n",
    "    # use this to split dataset in [folds] parts, test and train\n",
    "    skf = StratifiedKFold(n_splits=folds, random_state=folds_random_state, shuffle=folds_random_state is not None)\n",
    "\n",
    "    k = 0\n",
    "    accs = pd.DataFrame()\n",
    "    for train_index, test_index in skf.split(X, y[on_label]):\n",
    "\n",
    "        # get train and test set\n",
    "        X_train, X_test = X.take(train_index), X.take(test_index)\n",
    "        y_train, y_test = y.take(train_index), y.take(test_index)\n",
    "\n",
    "        # train the flat classifier\n",
    "        print(f\"Start training   fold {k}\")\n",
    "        flat_clf = train_flat(clf, X_train, y_train, on_label)\n",
    "\n",
    "        # predicting\n",
    "        print(f\"Start predicting fold {k}\")\n",
    "        y_pred_flat = flat_clf.predict(X_test)\n",
    "\n",
    "        # metrics\n",
    "        accs = accs.append(calc_metrics(y_test[on_label], y_pred_flat, f\"../results/flat_clf_f1-{k}.csv\"))\n",
    "        k += 1\n",
    "    \n",
    "    return accs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ccb813-5a8b-4f40-a2f4-e03f420a52d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training   fold 0\n",
      "Start predicting fold 0\n",
      "accuracy: 0.9023626975434205\n",
      "F1 micro-average: 0.9023626975434204\n",
      "F1 macro-average: 0.8430137881777549\n",
      "F1 weighted-average: 0.9004396258585396\n",
      "\n",
      "Start training   fold 1\n",
      "Start predicting fold 1\n",
      "accuracy: 0.9009389671361502\n",
      "F1 micro-average: 0.9009389671361502\n",
      "F1 macro-average: 0.8412668929414026\n",
      "F1 weighted-average: 0.8988779275416249\n",
      "\n",
      "\n",
      "AVERAGE ACCURACY AND F1 SCORES:\n",
      "accuracy               0.901651\n",
      "F1 micro-average       0.901651\n",
      "F1 macro-average       0.842140\n",
      "F1 weighted-average    0.899659\n",
      "dtype: float64\n",
      "CPU times: user 12min 1s, sys: 31.5 s, total: 12min 32s\n",
      "Wall time: 13min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "acc = flat(svm.LinearSVC(max_iter=2000), df, labels)\n",
    "\n",
    "print(\"\\nAVERAGE ACCURACY AND F1 SCORES:\")\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf40e188-0b04-4a8a-9379-c7018eba4d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a0ecfcc-953a-4628-8881-8ceed7754876",
   "metadata": {},
   "source": [
    "## Hyr classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a850bcd-d8c5-463d-ab64-2b680f41df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tree structure\n",
    "class Node:\n",
    "    def __init__(self, parent, class_name):\n",
    "        self.parent = parent\n",
    "        self.class_name = class_name\n",
    "        \n",
    "        self.clf = None\n",
    "        self.children = dict() # dict die resultaat van clf linkt aan een nieuwe node (met clf)\n",
    "        \n",
    "    def __str__(self):\n",
    "        if self.parent is None:\n",
    "            return \"Root\"\n",
    "        return f\"(class_name: {self.class_name}, parent: {self.parent})\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0a24c-3b76-46e6-a9ab-a9686fa95806",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyr training function\n",
    "## this builds the hyr tree using the flat classification function train_flat many times\n",
    "## the hyr tree consists of nodes which each have (except leaf nodes) a flat classifier which classifies into it's children\n",
    "\n",
    "def filter_data_on_class_name(df, labels, class_name, class_column_name):\n",
    "    keep_indices = labels[class_column_name] == class_name\n",
    "    return (df[keep_indices], labels[keep_indices])\n",
    "\n",
    "def train_hyr(clf, df, labels, node, parent_class=None, parent_class_column=None):\n",
    "    # train neural net to classify input in the child classes\n",
    "    \n",
    "    # get the child_class_column\n",
    "    if (parent_class is None or parent_class_column is None):\n",
    "        child_class_column = labels.columns[0]\n",
    "    else:\n",
    "        # make data smaller: remove all entries that do not belong to the parent_class\n",
    "        \n",
    "        df, labels = filter_data_on_class_name(df, labels, parent_class, parent_class_column)\n",
    "        \n",
    "        # get child_class_column\n",
    "        child_class_column_index = list(labels.columns).index(parent_class_column) + 1\n",
    "        if child_class_column_index >= len(labels.columns):\n",
    "            # we are at in a leaf of the hyr tree, there are no further child classes\n",
    "            return None\n",
    "        child_class_column = labels.columns[child_class_column_index]\n",
    "    \n",
    "    \n",
    "    # neural net that further classifies entries\n",
    "    unique_labels = pd.Series(labels[child_class_column]).unique()\n",
    "    if len(unique_labels) == 1:\n",
    "        # the subclass is the same as the parent class\n",
    "        node.clf = None\n",
    "    else:\n",
    "        # print()\n",
    "        # print(f\"parent_class: {parent_class}\")\n",
    "        node.clf = train_flat(clf, df, labels, child_class_column)\n",
    "    \n",
    "    # recursive step\n",
    "    for child_class in unique_labels: # todo: parallelize\n",
    "        child_node = Node(node, child_class)\n",
    "        train_hyr(clf, df, labels, child_node, child_class, child_class_column)\n",
    "        node.children[child_class] = child_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e6c50-79f2-49f7-a034-4913726876be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyr predicting function\n",
    "## given the hyr tree and an input, predict the cluster\n",
    "\n",
    "# recursive\n",
    "def predict_hyr(node, X_test):\n",
    "    #### Printing\n",
    "    spaces = 1\n",
    "    it_node = node\n",
    "    while it_node.parent is not None:\n",
    "        it_node = it_node.parent\n",
    "        spaces += 2\n",
    "    # print((spaces*\"--\") + f\"{node.class_name if node.parent is not None else 'Root' }\")\n",
    "    ####\n",
    "    \n",
    "    # the tree goes further down, but there is only 1 subclass and thus no further classifier needs to be executed\n",
    "    if node.clf is None:\n",
    "        child_node = list(node.children.values())[0]\n",
    "        y_test = pd.DataFrame(index=X_test.index, columns=[0]).fillna(child_node.class_name) \n",
    "        #print(child_node.class_name)\n",
    "    else:\n",
    "        y_test = pd.DataFrame(node.clf.predict(X_test))\n",
    "        y_test.index = X_test.index # keep original indices\n",
    "    \n",
    "    # we are in a leaf when the children dont have any children themselves\n",
    "    # (We dont need to call predict on a child if they wont be able to futher classify to their children\n",
    "    if list(node.children.values())[0].children == {}:\n",
    "        return y_test\n",
    "    else:\n",
    "        # the children do have a clf to further classify, so further classify\n",
    "        predictions = []\n",
    "        for label, child_node in node.children.items():\n",
    "            new_X_test = X_test[y_test[0] == label]\n",
    "            predictions.append(predict_hyr(child_node, new_X_test))\n",
    "        return pd.concat(predictions)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af3ec4e-1c0a-4034-bb1a-7a81ceb93028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyr(clf, X, y, on_label=\"cluster\", folds=2, folds_random_state=1337):\n",
    "    # use this to split dataset in 2 parts, test and train\n",
    "    skf = StratifiedKFold(n_splits=folds, random_state=folds_random_state, shuffle=folds_random_state is not None)\n",
    "\n",
    "    k = 0\n",
    "    accs = pd.DataFrame()\n",
    "    for train_index, test_index in skf.split(X, y[on_label]):\n",
    "\n",
    "        # get train and test set\n",
    "        X_train, X_test = X.take(train_index), X.take(test_index)\n",
    "        y_train, y_test = y.take(train_index), y.take(test_index)\n",
    "\n",
    "        # train the flat classifier\n",
    "        print(\"Start training\")\n",
    "        root = Node(None, \"\")\n",
    "        train_hyr(clf, X_train, y_train, root)\n",
    "\n",
    "        print(root)\n",
    "        # predicting\n",
    "        print(\"Start predicting\")\n",
    "        y_pred_hyr = predict_hyr(root, X_test).sort_index(ascending=True) # sort data to calculate metrix\n",
    "\n",
    "        # metrics\n",
    "        accs = accs.append(calc_metrics(y_test[on_label], y_pred_hyr[0], f\"../results/hyr_clf_f1-{k}.csv\"))\n",
    "        k += 1\n",
    "\n",
    "    return accs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e0e1c-368e-4311-8876-754b3e7e2a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Root\n",
      "Start predicting\n",
      "accuracy: 0.9018932874354562\n",
      "F1 micro-average: 0.9018932874354562\n",
      "F1 macro-average: 0.8465664717429424\n",
      "F1 weighted-average: 0.8997948064272631\n",
      "\n",
      "Start training\n",
      "Root\n",
      "Start predicting\n",
      "accuracy: 0.9020344287949922\n",
      "F1 micro-average: 0.9020344287949922\n",
      "F1 macro-average: 0.8420932014001663\n",
      "F1 weighted-average: 0.9003196202455704\n",
      "\n",
      "\n",
      "AVERAGE ACCURACY AND F1 SCORES:\n",
      "accuracy               0.901964\n",
      "F1 micro-average       0.901964\n",
      "F1 macro-average       0.844330\n",
      "F1 weighted-average    0.900057\n",
      "dtype: float64\n",
      "CPU times: user 8min 30s, sys: 1min 16s, total: 9min 46s\n",
      "Wall time: 10min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "accs = hyr(svm.LinearSVC(max_iter=2000), df, labels)\n",
    "\n",
    "print(\"\\nAVERAGE ACCURACY AND F1 SCORES:\")\n",
    "print(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816374fe-cdda-4d91-a8b4-e4f4cf274f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35368773-4fe9-422b-9124-07a6ff7a1942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
