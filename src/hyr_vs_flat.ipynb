{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a5db6e-459b-432a-950a-85f11269b765",
   "metadata": {},
   "source": [
    "# Comparing hyr classification with flat classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9cdf4c-0c12-4abf-8589-050a206b245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn import datasets, neighbors, metrics, tree, svm, preprocessing, model_selection, ensemble\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd34153-6622-4b85-b484-e33b8ad0b95e",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "This data has been preprocessed in pickle.ipynb and stored in .pkl files.\n",
    "This makes for much faster loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce685f8-b748-4af6-9e3a-3afb4a163eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 2.47 s, total: 2.47 s\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_pickle(\"../data/Lauren/df.pkl\")\n",
    "labels = pd.read_pickle(\"../data/Lauren/labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b52c5b-59dc-4153-b557-2ff634a0c473",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68d817d-3df8-43b1-9c44-d2d371eff4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_test, y_pred, f1_file_name=None):\n",
    "    unique_labels_df = pd.DataFrame(pd.Series(y_test).unique())\n",
    "    f1 = pd.DataFrame(metrics.f1_score(y_test, y_pred, average=None, labels = unique_labels_df[0]))\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"accuracy: {acc}\")\n",
    "    print(f\"F1 micro-average: {metrics.f1_score(y_test_set['cluster'], y_pred, average='micro')}\")\n",
    "    print(f\"F1 macro-average: {metrics.f1_score(y_test_set['cluster'], y_pred, average='macro')}\")\n",
    "    print(f\"F1 weighted-average: {metrics.f1_score(y_test_set['cluster'], y_pred, average='weighted')}\")\n",
    "    print()\n",
    "    \n",
    "    # seperate f1 score for each label\n",
    "    f1_labeled = pd.concat([unique_labels_df[0], f1[0]], axis=1, keys=['class', 'f1_per_class'])\n",
    "    print(f1_labeled)\n",
    "    \n",
    "    # save seperate f1 scores\n",
    "    if f1_file_name is not None:\n",
    "        f1_labeled.to_csv(f1_file_name, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03576bb0-08c2-4303-9728-f007c46b9021",
   "metadata": {},
   "source": [
    "## Flat classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c494023-1b4d-41cb-85c2-df04bb195d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a linear multi label classifier\n",
    "# df: X\n",
    "# labels: multiple columns, one of which will be y\n",
    "# class_column_name: the name of the column in labels that will be y\n",
    "def train_linear_nn(df, labels, class_column_name): # todo: give linear classifier as argument\n",
    "    # only keep the needed column\n",
    "    drop_columns = filter(lambda col: col != class_column_name , labels.columns)\n",
    "    labels = labels.drop(columns = drop_columns).values.ravel()\n",
    "     \n",
    "    X_train, y_train = df, labels\n",
    "        \n",
    "    # 1vRest training\n",
    "    print(f\"Start training {class_column_name} entries with multiclass output: {pd.Series(y_train).unique()}\")\n",
    "    lin_clf = svm.LinearSVC()\n",
    "    lin_clf.fit(X_train, y_train)\n",
    "    \n",
    "    return lin_clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25ccb813-5a8b-4f40-a2f4-e03f420a52d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Start training cluster entries with multiclass output: ['Vip Arhgap36 Hmcn1' 'Vip Crispld2 Htr2c' 'Lamp5 Plch2 Dock5'\n",
      " 'Sncg Vip Itih5' 'Vip Crispld2 Kcne4' 'Vip Lect1 Oxtr' 'Lamp5 Lsp1'\n",
      " 'Vip Chat Htr1f' 'Vip Pygm C1ql1' 'Lamp5 Krt73' 'Pvalb Tpbg'\n",
      " 'Lamp5 Fam19a1 Tmem182' 'Lamp5 Fam19a1 Pax6' 'Vip Igfbp6 Car10'\n",
      " 'Lamp5 Ntn1 Npy2r' 'Vip Igfbp6 Pltp' 'Pvalb Reln Tac1' 'Sst Chrna2 Ptgdr'\n",
      " 'Sst Hpse Cbln4' 'Sst Hpse Sema3c' 'Vip Igfbp4 Mab21l1' 'Pvalb Vipr2'\n",
      " 'Sst Rxfp1 Prdm8' 'Sst Nr2f2 Necab1' 'Pvalb Calb1 Sst' 'Sst Chrna2 Glra3'\n",
      " 'Sncg Gpr50' 'Pvalb Gabrg1' 'L6 CT VISp Nxph2 Wls' 'L6 CT VISp Ctxn3 Sla'\n",
      " 'L6 CT VISp Krt80 Sla' 'L6 CT VISp Gpr139' 'L6 CT VISp Ctxn3 Brinp3'\n",
      " 'L6b VISp Col8a1 Rxfp1' 'L6 IT VISp Penk Col27a1' 'L6 IT VISp Penk Fst'\n",
      " 'L6 IT VISp Col23a1 Adamts2' 'Sst Crhr2 Efemp1' 'L2/3 IT VISp Adamts2'\n",
      " 'L2/3 IT VISp Rrad' 'Sst Tac1 Tacr3' 'L2/3 IT VISp Agmat'\n",
      " 'Sst Calb2 Pdlim5' 'Sst Rxfp1 Eya1' 'Lamp5 Lhx6' 'Sst Chodl'\n",
      " 'Sst Tac1 Htr1d' 'Vip Ptprt Pkp2' 'Sncg Slc17a8' 'Pvalb Gpr149 Islr'\n",
      " 'Sst Mme Fam114a1' 'Sst Tac2 Tacstd2' 'Pvalb Th Sst'\n",
      " 'Sst Crh 4930553C11Rik ' 'Pvalb Sema3e Kank4' 'L6 IT VISp Col18a1'\n",
      " 'L4 IT VISp Rspo1' 'L5 NP VISp Trhr Met' 'L5 NP VISp Trhr Cpne7'\n",
      " 'L5 IT VISp Batf3' 'L6 IT VISp Car3' 'Vip Rspo4 Rxfp1 Chat'\n",
      " 'Vip Gpc3 Slc18a3' 'Pvalb Reln Itm2a' 'Serpinf1 Aqp5 Vip'\n",
      " 'Sst Myh8 Fibin' 'Sst Myh8 Etv1 ' 'Sst Esm1' 'Serpinf1 Clrn1'\n",
      " 'Vip Col15a1 Pde1a' 'Sncg Vip Nptx2' 'Vip Lmo1 Myl1'\n",
      " 'L5 IT VISp Hsd11b1 Endou' 'L5 PT VISp C1ql2 Ptgfr' 'L5 IT VISp Col27a1'\n",
      " 'Sst Nts' 'Sst Tac2 Myh4' 'Pvalb Akr1c18 Ntf3' 'Vip Lmo1 Fam159b'\n",
      " 'L5 PT VISp Krt80' 'Astro Aqp4' 'L6 CT ALM Nxph2 Sla'\n",
      " 'L6b VISp Col8a1 Rprm' 'Vip Rspo1 Itga4' 'L5 IT VISp Whrn Tox2'\n",
      " 'L5 PT VISp Chrna6' 'L5 IT VISp Col6a1 Fezf2' 'L5 PT VISp C1ql2 Cdh13'\n",
      " 'L5 PT VISp Lgr5' 'Sst Calb2 Necab1' 'L6b P2ry12' 'L6b VISp Mup5'\n",
      " 'L6b VISp Crh']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'calc_metrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calc_metrix' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train on half the dataset, test on the other and calculate the metrics\n",
    "\n",
    "# use this to split dataset in 2 parts, test and train\n",
    "skf = StratifiedKFold(n_splits=2, random_state=1337, shuffle=True)\n",
    "\n",
    "for train_index, test_index in skf.split(df, labels[\"cluster\"]):\n",
    "\n",
    "    # get train and test set\n",
    "    X_train, X_test = df.take(train_index), df.take(test_index)\n",
    "    y_train, y_test = labels.take(train_index), labels.take(test_index)\n",
    "\n",
    "    # train the flat classifier\n",
    "    print(\"Start training\")\n",
    "    flat_clf = train_linear_nn(X_train, y_train, \"cluster\")\n",
    "\n",
    "    # predicting\n",
    "    print(\"Start predicting\")\n",
    "    y_pred_flat_clf = flat_clf.predict(X_test)\n",
    "\n",
    "    # metrics\n",
    "    calc_metrics(y_test[\"cluster\"], y_pred_flat_clf, \"../results/flat_clf_f1.csv\")\n",
    "    \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce38bd4a-5bac-4ba4-9d58-56734f500736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a850bcd-d8c5-463d-ab64-2b680f41df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tree structure\n",
    "class Node:\n",
    "    def __init__(self, parent, class_name):\n",
    "        self.parent = parent\n",
    "        self.class_name = class_name\n",
    "        \n",
    "        self.clf = None\n",
    "        self.children = dict() # dict die resultaat van clf linkt aan een nieuwe node (met clf)\n",
    "        \n",
    "    def __str__(self):\n",
    "        if self.parent is None:\n",
    "            return \"Root\"\n",
    "        return f\"(class_name: {self.class_name}, parent: {self.parent})\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0a24c-3b76-46e6-a9ab-a9686fa95806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_on_class_name(df, labels, class_name, class_column_name):\n",
    "    keep_indices = labels[class_column_name] == class_name\n",
    "    return (df[keep_indices], labels[keep_indices])\n",
    "\n",
    "def train_hyr_nn(df, labels, node, parent_class=None, parent_class_column=None):\n",
    "    # train neural net to classify input in the child classes\n",
    "    \n",
    "    # get the child_class_column\n",
    "    if (parent_class is None or parent_class_column is None):\n",
    "        child_class_column = labels.columns[0]\n",
    "    else:\n",
    "        # make data smaller: remove all entries that do not belong to the parent_class\n",
    "        \n",
    "        df, labels = filter_data_on_class_name(df, labels, parent_class, parent_class_column)\n",
    "        \n",
    "        # get child_class_column\n",
    "        child_class_column_index = list(labels.columns).index(parent_class_column) + 1\n",
    "        if child_class_column_index >= len(labels.columns):\n",
    "            # we are at in a leaf of the hyr tree, there are no further child classes\n",
    "            return None\n",
    "        child_class_column = labels.columns[child_class_column_index]\n",
    "    \n",
    "    \n",
    "    # neural net that further classifies entries\n",
    "    unique_labels = pd.Series(labels[child_class_column]).unique()\n",
    "    if len(unique_labels) == 1:\n",
    "        # the subclass is the same as the parent class\n",
    "        node.clf = None\n",
    "    else:\n",
    "        print()\n",
    "        print(f\"parent_class: {parent_class}\")\n",
    "        node.clf = train_linear_nn(df, labels, child_class_column)\n",
    "    \n",
    "    # recursive step\n",
    "    for child_class in unique_labels: # todo: parallelize\n",
    "        child_node = Node(node, child_class)\n",
    "        train_hyr_nn(df, labels, child_node, child_class, child_class_column)\n",
    "        node.children[child_class] = child_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8955587-27f4-4ccc-a629-ff5637249879",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get part of data where all cluster types are represented\n",
    "\n",
    "drop_columns = list(filter(lambda col: col != \"cluster\" , labels.columns))\n",
    "dclusters = labels.drop(columns = drop_columns).values.ravel()\n",
    "\n",
    "# only use part (1/5) of data for training and 1/5th for testing\n",
    "trained = False\n",
    "skf = StratifiedKFold(n_splits=2, random_state=1337, shuffle=True)\n",
    "for train_index, test_index in skf.split(df, dclusters):\n",
    "    if not trained:\n",
    "        print(\"TRAINING\")\n",
    "        root = Node(None, \"\")\n",
    "        train_hyr_nn(df.take(test_index), labels.take(test_index), root)\n",
    "        trained = True\n",
    "    else: \n",
    "        print(\"SETTING TEST SET\")\n",
    "        X_test_set = df.take(test_index)\n",
    "        y_test_set = labels.take(test_index)\n",
    "        break\n",
    "\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e6c50-79f2-49f7-a034-4913726876be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the hyr nn tree and an input, predict the cluster\n",
    "\n",
    "# recursive\n",
    "def predict(node, X_test):\n",
    "    #### Printing\n",
    "    spaces = 1\n",
    "    it_node = node\n",
    "    while it_node.parent is not None:\n",
    "        it_node = it_node.parent\n",
    "        spaces += 2\n",
    "    print((spaces*\"--\") + f\"{node.class_name if node.parent is not None else 'Root' }\")\n",
    "    ####\n",
    "    \n",
    "    # the tree goes further down, but there is only 1 subclass and thus no further classifier needs to be executed\n",
    "    if node.clf is None:\n",
    "        child_node = list(node.children.values())[0]\n",
    "        y_test = pd.DataFrame(index=X_test.index, columns=[0]).fillna(child_node.class_name) \n",
    "        #print(child_node.class_name)\n",
    "    else:\n",
    "        y_test = pd.DataFrame(node.clf.predict(X_test))\n",
    "        y_test.index = X_test.index # keep original indices\n",
    "    \n",
    "    # we are in a leaf when the children dont have any children themselves\n",
    "    # (We dont need to call predict on a child if they wont be able to futher classify to their children\n",
    "    if list(node.children.values())[0].children == {}:\n",
    "        return y_test\n",
    "    else:\n",
    "        # the children do have a clf to further classify, so further classify\n",
    "        predictions = []\n",
    "        for label, child_node in node.children.items():\n",
    "            new_X_test = X_test[y_test[0] == label]\n",
    "            predictions.append(predict(child_node, new_X_test))\n",
    "        return pd.concat(predictions)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47464bc-a40b-4c82-95af-d8943ebb3515",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "y_pred_hyr = predict(root, X_test_set).sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0310e6d0-c48d-4dd3-b3f3-ef28594cadfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = metrics.f1_score(y_test_set[\"cluster\"], y_pred_hyr[0], average=None, labels = unique_labels_df[0])\n",
    "acc = metrics.accuracy_score(y_test_set[\"cluster\"], y_pred_hyr[0])\n",
    "\n",
    "unique_labels_df = pd.DataFrame(pd.Series(y_test_set[\"cluster\"]).unique())\n",
    "\n",
    "f1_df = pd.DataFrame(f1)\n",
    "f1_df_labeled = pd.concat([unique_labels_df, f1_df], axis=1, keys=['dcluster', 'f1_per_dcluster'])\n",
    "print(f1_df_labeled)\n",
    "print(f\"acc: {acc}\")\n",
    "print()\n",
    "print(f\"F1 micro-average: {metrics.f1_score(y_test_set['cluster'], y_pred_hyr[0], average='micro')}\")\n",
    "print(f\"F1 macro-average: {metrics.f1_score(y_test_set['cluster'], y_pred_hyr[0], average='macro')}\")\n",
    "print(f\"F1 weighted-average: {metrics.f1_score(y_test_set['cluster'], y_pred_hyr[0], average='weighted')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
