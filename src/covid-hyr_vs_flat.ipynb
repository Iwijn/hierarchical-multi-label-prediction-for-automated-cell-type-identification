{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a5db6e-459b-432a-950a-85f11269b765",
   "metadata": {},
   "source": [
    "# Comparing hyr classification with flat classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b9cdf4c-0c12-4abf-8589-050a206b245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn import datasets, neighbors, metrics, tree, svm, preprocessing, model_selection, ensemble\n",
    "from sklearn.base import clone as sklearn_clone\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd34153-6622-4b85-b484-e33b8ad0b95e",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "This data has been preprocessed in pickle.ipynb and stored in .pkl files.\n",
    "This makes for much faster loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce685f8-b748-4af6-9e3a-3afb4a163eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.88 s, total: 1.88 s\n",
      "Wall time: 1.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_pickle(\"../data/Lauren/covid_df.pkl\")\n",
    "labels = pd.read_pickle(\"../data/Lauren/covid_labels.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b52c5b-59dc-4153-b557-2ff634a0c473",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68d817d-3df8-43b1-9c44-d2d371eff4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_test, y_pred, f1_file_name=None):\n",
    "    unique_labels_df = pd.DataFrame(pd.Series(y_test).unique())\n",
    "    f1 = pd.DataFrame(metrics.f1_score(y_test, y_pred, average=None, labels = unique_labels_df[0]))\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"accuracy: {acc}\")\n",
    "    f1_micro = metrics.f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    f1_weighted = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"F1 micro-average: {f1_micro}\")\n",
    "    print(f\"F1 macro-average: {f1_macro}\")\n",
    "    print(f\"F1 weighted-average: {f1_weighted}\")\n",
    "    print()\n",
    "    \n",
    "    # seperate f1 score for each label\n",
    "    f1_labeled = pd.concat([unique_labels_df[0], f1[0]], axis=1, keys=['class', 'f1_per_class'])\n",
    "    # print(f1_labeled)\n",
    "    \n",
    "    # save seperate f1 scores\n",
    "    if f1_file_name is not None:\n",
    "        f1_labeled.to_csv(f1_file_name, index=False)\n",
    "    \n",
    "    return pd.DataFrame([[acc, f1_micro, f1_macro, f1_weighted]], columns=[\"accuracy\", \"F1 micro-average\", \"F1 macro-average\", \"F1 weighted-average\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03576bb0-08c2-4303-9728-f007c46b9021",
   "metadata": {},
   "source": [
    "## Flat classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba3dfcf-d72d-4024-9a53-dd8aaf99b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatify(multi_y):\n",
    "    try:\n",
    "        if multi_y.shape[1] == 1:\n",
    "            return multi_y\n",
    "    except:\n",
    "        return multi_y\n",
    "\n",
    "    def most_specific_class(row):\n",
    "        empty_found = False\n",
    "        for i in range(len(row)):\n",
    "            if row.iloc[i] is None or row.iloc[i] == \"\":\n",
    "                empty_found = True\n",
    "                break\n",
    "        return row.iloc[i-1] if empty_found else row.iloc[i]\n",
    "    return multi_y.apply(lambda row: most_specific_class(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c494023-1b4d-41cb-85c2-df04bb195d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a flat multi label classifier\n",
    "# df: X\n",
    "# labels: multiple columns\n",
    "# class_column_name: the name of the column in labels that will be y\n",
    "def train_flat(clf, X_train, labels, class_column_name=None): # todo: give linear classifier as argument\n",
    "    if class_column_name is None:\n",
    "        y_train = flatify(labels)\n",
    "    else:\n",
    "        # only keep the needed column\n",
    "        drop_columns = filter(lambda col: col != class_column_name , labels.columns)\n",
    "        y_train = labels.drop(columns = drop_columns).values.ravel()\n",
    "    \n",
    "    # copy the model, important for hierarchical\n",
    "    clf = sklearn_clone(clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "371c787b-b309-4434-85c5-35ce037cd59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat(clf, X, y, folds=2, folds_random_state=1337):\n",
    "# use this to split dataset in [folds] parts, test and train\n",
    "# folds = 5\n",
    "# folds_random_state = 1337\n",
    "# y = labels\n",
    "# X = df\n",
    "# clf = svm.LinearSVC(max_iter=2000)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=folds, random_state=folds_random_state, shuffle=folds_random_state is not None)\n",
    "\n",
    "    k = 0\n",
    "    accs = pd.DataFrame()\n",
    "    y_flat = flatify(y)\n",
    "    for train_index, test_index in skf.split(X, y_flat):\n",
    "\n",
    "        # get train and test set\n",
    "        X_train, X_test = X.take(train_index), X.take(test_index)\n",
    "        y_train, y_test = y_flat.take(train_index), y_flat.take(test_index)\n",
    "\n",
    "        # train the flat classifier\n",
    "        print(f\"Start training   fold {k}\")\n",
    "        flat_clf = train_flat(clf, X_train, y_train)\n",
    "\n",
    "        # predicting\n",
    "        print(f\"Start predicting fold {k}\")\n",
    "        y_pred_flat = flat_clf.predict(X_test)\n",
    "\n",
    "        # metrics\n",
    "        accs = accs.append(calc_metrics(y_test, y_pred_flat, f\"../results/flat_clf_f1-{k}.csv\"))\n",
    "\n",
    "        # break\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    return accs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25ccb813-5a8b-4f40-a2f4-e03f420a52d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training   fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting fold 0\n",
      "accuracy: 0.661954261954262\n",
      "F1 micro-average: 0.661954261954262\n",
      "F1 macro-average: 0.47913315198013023\n",
      "F1 weighted-average: 0.6541929299806176\n",
      "\n",
      "Start training   fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting fold 1\n",
      "accuracy: 0.655093555093555\n",
      "F1 micro-average: 0.655093555093555\n",
      "F1 macro-average: 0.4754821522417491\n",
      "F1 weighted-average: 0.6489203160856086\n",
      "\n",
      "\n",
      "AVERAGE ACCURACY AND F1 SCORES:\n",
      "accuracy               0.658524\n",
      "F1 micro-average       0.658524\n",
      "F1 macro-average       0.477308\n",
      "F1 weighted-average    0.651557\n",
      "dtype: float64\n",
      "CPU times: user 16min 53s, sys: 7.77 s, total: 17min 1s\n",
      "Wall time: 16min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "acc = flat(svm.LinearSVC(max_iter=10000), df, labels, folds=2)\n",
    "\n",
    "print(\"\\nAVERAGE ACCURACY AND F1 SCORES:\")\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ecfcc-953a-4628-8881-8ceed7754876",
   "metadata": {},
   "source": [
    "## Hyr classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a850bcd-d8c5-463d-ab64-2b680f41df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tree structure\n",
    "class Node:\n",
    "    def __init__(self, parent, class_name):\n",
    "        self.parent = parent\n",
    "        self.class_name = class_name\n",
    "        \n",
    "        self.clf = None\n",
    "        self.children = dict() # dict die resultaat van clf linkt aan een nieuwe node (met clf)\n",
    "        \n",
    "    def __str__(self):\n",
    "        if self.parent is None:\n",
    "            return \"Root\"\n",
    "        return f\"(class_name: {self.class_name}, parent: {self.parent})\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bad0a24c-3b76-46e6-a9ab-a9686fa95806",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyr training function\n",
    "## this builds the hyr tree using the flat classification function train_flat many times\n",
    "## the hyr tree consists of nodes which each have (except leaf nodes) a flat classifier which classifies into it's children\n",
    "\n",
    "def filter_data_on_class_name(df, labels, class_name, class_column_name):\n",
    "    keep_indices = labels[class_column_name] == class_name\n",
    "    return (df[keep_indices], labels[keep_indices])\n",
    "\n",
    "def train_hyr(clf, df, labels, node, parent_class=None, parent_class_column=None):\n",
    "    # train neural net to classify input in the child classes\n",
    "    \n",
    "    # get the child_class_column\n",
    "    if (parent_class is None or parent_class_column is None):\n",
    "        child_class_column = labels.columns[0]\n",
    "    else:\n",
    "        # make data smaller: remove all entries that do not belong to the parent_class\n",
    "        \n",
    "        df, labels = filter_data_on_class_name(df, labels, parent_class, parent_class_column)\n",
    "        \n",
    "        # get child_class_column\n",
    "        child_class_column_index = list(labels.columns).index(parent_class_column) + 1\n",
    "        if child_class_column_index >= len(labels.columns):\n",
    "            # we are at in a leaf of the hyr tree, there are no further child classes\n",
    "            return None\n",
    "        child_class_column = labels.columns[child_class_column_index]\n",
    "    \n",
    "    \n",
    "    # neural net that further classifies entries\n",
    "    unique_labels = pd.Series(labels[child_class_column]).unique()\n",
    "    if len(unique_labels) == 1:\n",
    "        # the subclass is the same as the parent class\n",
    "        node.clf = None\n",
    "    else:\n",
    "        # print()\n",
    "        # print(f\"parent_class: {parent_class}\")\n",
    "        node.clf = train_flat(clf, df, labels, child_class_column)\n",
    "    \n",
    "    # recursive step\n",
    "    for child_class in unique_labels: # todo: parallelize\n",
    "        child_node = Node(node, child_class)\n",
    "        train_hyr(clf, df, labels, child_node, child_class, child_class_column)\n",
    "        node.children[child_class] = child_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b0e6c50-79f2-49f7-a034-4913726876be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyr predicting function\n",
    "## given the hyr tree and an input, predict the cluster\n",
    "\n",
    "# recursive\n",
    "def predict_hyr(node, X_test):\n",
    "    #### Printing\n",
    "    spaces = 1\n",
    "    it_node = node\n",
    "    while it_node.parent is not None:\n",
    "        it_node = it_node.parent\n",
    "        spaces += 2\n",
    "    # print((spaces*\"--\") + f\"{node.class_name if node.parent is not None else 'Root' }\")\n",
    "    ####\n",
    "    \n",
    "    # the tree goes further down, but there is only 1 subclass and thus no further classifier needs to be executed\n",
    "    if node.clf is None:\n",
    "        child_node = list(node.children.values())[0]\n",
    "        if child_node.class_name != \"\":\n",
    "            name = child_node.class_name\n",
    "        elif node.class_name != \"\":\n",
    "            name = node.class_name\n",
    "        else:\n",
    "            name = node.parent.class_name\n",
    "        y_test = pd.DataFrame(index=X_test.index, columns=[0]).fillna(name)\n",
    "        #print(child_node.class_name)\n",
    "    else:\n",
    "        y_test = pd.DataFrame(node.clf.predict(X_test))\n",
    "        y_test.index = X_test.index # keep original indices\n",
    "    \n",
    "    # we are in a leaf when the children dont have any children themselves\n",
    "    # (We dont need to call predict on a child if they wont be able to futher classify to their children\n",
    "    if list(node.children.values())[0].children == {} or len(list(node.children.keys())) == 1:\n",
    "        return y_test\n",
    "    else:\n",
    "        # the children do have a clf to further classify, so further classify\n",
    "        predictions = []\n",
    "        for label, child_node in node.children.items():\n",
    "            new_X_test = X_test[y_test[0] == label]\n",
    "            predictions.append(predict_hyr(child_node, new_X_test))\n",
    "        return pd.concat(predictions)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8af3ec4e-1c0a-4034-bb1a-7a81ceb93028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyr(clf, X, y, on_label=None, folds=2, folds_random_state=1337):\n",
    "# use this to split dataset in 2 parts, test and train\n",
    "# folds = 5\n",
    "# folds_random_state = 1337\n",
    "# y = labels.fillna(\"\")\n",
    "# X = df\n",
    "# clf = svm.LinearSVC(max_iter=2000)\n",
    "# df.index = labels.index\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=folds, random_state=folds_random_state, shuffle=folds_random_state is not None)\n",
    "\n",
    "    k = 0\n",
    "    accs = pd.DataFrame()\n",
    "    y_flat = flatify(y)\n",
    "    for train_index, test_index in skf.split(X, y_flat):\n",
    "\n",
    "        # get train and test set\n",
    "        X_train, X_test = X.take(train_index), X.take(test_index)\n",
    "        y_train, y_test = y.take(train_index), y.take(test_index)\n",
    "\n",
    "        # train the flat classifier\n",
    "        print(\"Start training\")\n",
    "        root = Node(None, \"\")\n",
    "        train_hyr(clf, X_train, y_train, root)\n",
    "\n",
    "        print(root)\n",
    "        # predicting\n",
    "        print(\"Start predicting\")\n",
    "        y_pred_hyr = predict_hyr(root, X_test).sort_index(ascending=True) # sort data to calculate metrics\n",
    "\n",
    "        # metrics\n",
    "        accs = accs.append(calc_metrics(flatify(y_test), y_pred_hyr[0], f\"../results/hyr_clf_f1-{k}.csv\"))\n",
    "        k += 1\n",
    "        # break\n",
    "\n",
    "    return accs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c11e0e1c-368e-4311-8876-754b3e7e2a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root\n",
      "Start predicting\n",
      "accuracy: 0.6693347193347193\n",
      "F1 micro-average: 0.6693347193347193\n",
      "F1 macro-average: 0.4811042365138301\n",
      "F1 weighted-average: 0.6691812824523582\n",
      "\n",
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root\n",
      "Start predicting\n",
      "accuracy: 0.6566528066528067\n",
      "F1 micro-average: 0.6566528066528067\n",
      "F1 macro-average: 0.46832613666563266\n",
      "F1 weighted-average: 0.6588303452197658\n",
      "\n",
      "\n",
      "AVERAGE ACCURACY AND F1 SCORES:\n",
      "accuracy               0.662994\n",
      "F1 micro-average       0.662994\n",
      "F1 macro-average       0.474715\n",
      "F1 weighted-average    0.664006\n",
      "dtype: float64\n",
      "CPU times: user 11min 7s, sys: 1min 18s, total: 12min 26s\n",
      "Wall time: 11min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.index = labels.index\n",
    "accs = hyr(svm.LinearSVC(max_iter=4000), df, labels.fillna(\"\"))\n",
    "\n",
    "print(\"\\nAVERAGE ACCURACY AND F1 SCORES:\")\n",
    "print(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "816374fe-cdda-4d91-a8b4-e4f4cf274f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                Neutrophils\n",
       "3                    exhaust\n",
       "7                   Alveolar\n",
       "16                Unspec-CD8\n",
       "19                 recruited\n",
       "                ...         \n",
       "19258              Undefined\n",
       "19260                Cytotox\n",
       "19268                 naive1\n",
       "19279            Neutrophils\n",
       "19280    recruited-activated\n",
       "Length: 3848, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatify(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35368773-4fe9-422b-9124-07a6ff7a1942",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3848, 832]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_226821/2353344578.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalc_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_hyr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_226821/999929699.py\u001b[0m in \u001b[0;36mcalc_metrics\u001b[0;34m(y_test, y_pred, f1_file_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_file_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0munique_labels_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \"\"\"\n\u001b[0;32m-> 1113\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1114\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \"\"\"\n\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1336\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1339\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3848, 832]"
     ]
    }
   ],
   "source": [
    "calc_metrics(flatify(y_test), y_pred_hyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f168478-a855-4f11-90d7-3dcd973a271c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6673596673596673\n",
      "F1 micro-average: 0.6673596673596673\n",
      "F1 macro-average: 0.46389954870517325\n",
      "F1 weighted-average: 0.669690010943891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_hyr = predict_hyr(root, X_test).sort_index(ascending=True) # sort data to calculate metrics\n",
    "\n",
    "    # metrics\n",
    "accs = accs.append(calc_metrics(flatify(y_test), y_pred_hyr[0], f\"../results/hyr_clf_f1-{k}.csv\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f16bc06-89fe-4464-83bb-b4970bd74b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutrophils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exhaust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alveolar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Unspec-CD8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>recruited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19258</th>\n",
       "      <td>Neutrophils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19260</th>\n",
       "      <td>exhaust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19268</th>\n",
       "      <td>naive1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19279</th>\n",
       "      <td>Neutrophils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19280</th>\n",
       "      <td>recruited-activated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3848 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "0              Neutrophils\n",
       "3                  exhaust\n",
       "7                 Alveolar\n",
       "16              Unspec-CD8\n",
       "19               recruited\n",
       "...                    ...\n",
       "19258          Neutrophils\n",
       "19260              exhaust\n",
       "19268               naive1\n",
       "19279          Neutrophils\n",
       "19280  recruited-activated\n",
       "\n",
       "[3848 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_hyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f755a8e6-1f4b-4645-aae5-88d03c096ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CD4'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatify(y_test)[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ff9a2b2-36c4-4376-950d-7c06cebaa7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Unspec-CD4-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>naive1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19073</th>\n",
       "      <td>naive2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19115</th>\n",
       "      <td>naive1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19117</th>\n",
       "      <td>Unspec-CD4-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19123</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19268</th>\n",
       "      <td>naive1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "31                 \n",
       "74                 \n",
       "117    Unspec-CD4-1\n",
       "139                \n",
       "172          naive1\n",
       "...             ...\n",
       "19073        naive2\n",
       "19115        naive1\n",
       "19117  Unspec-CD4-1\n",
       "19123              \n",
       "19268        naive1\n",
       "\n",
       "[832 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_hyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce996f-9adb-429a-9bb8-f953f8393339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
