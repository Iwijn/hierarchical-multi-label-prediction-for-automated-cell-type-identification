{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6797478-9721-4416-97af-f512e368c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn import datasets, neighbors, metrics, tree, svm, preprocessing, model_selection, ensemble\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c59c4a-7324-4cbf-b9a2-921ba0acb2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#\n",
    "## load labels\n",
    "#labels = pd.read_csv('../data/Lauren/Labels.csv')\n",
    "##labels.head() # to display the first 5 lines of loaded data\n",
    "#\n",
    "## load data\n",
    "#df = pd.read_csv('../data/Lauren/500_PBMC_3p_LT_Chromium_X_metrics_summary.csv') # takes about 5min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8096e53a-5b74-4a69-8873-4e072d0ffe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "## filter out certain data\n",
    "def gereral_data_filter(df, labels, filter_on, amount_higher_than):\n",
    "    ## Filter info\n",
    "    classes_count = labels.groupby(filter_on).count()\n",
    "    classes_to_keep = list(classes_count[classes_count[classes_count.columns[-1]] >= amount_higher_than].index)\n",
    "    keep_indices = labels[filter_on].isin(classes_to_keep)\n",
    "    \n",
    "    ## delete entries part of class that's too small, remove names column\n",
    "    return (df[keep_indices].drop(columns=[\"Unnamed: 0\"]), labels[keep_indices])\n",
    "\n",
    "#df, labels = gereral_data_filter(df, labels, \"cluster\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f347f4-9fcc-4ee8-ba20-eec3d46be640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 2.48 s, total: 2.5 s\n",
      "Wall time: 2.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_pickle(\"../data/Lauren/df.pkl\")\n",
    "labels = pd.read_pickle(\"../data/Lauren/labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46edd506-b284-4ba6-bfdd-a3ed1fe8ef80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c663c41e-504a-4c07-9e38-038ce803cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_linear_nn(df, labels, class_column_name): # todo: give linear classifier as argument\n",
    "    # only keep the needed column\n",
    "    drop_columns = filter(lambda col: col != class_column_name , labels.columns)\n",
    "    labels = labels.drop(columns = drop_columns).values.ravel()\n",
    "    \n",
    "    # use this to split dataset in 2 parts, test and train\n",
    "    skf = StratifiedKFold(n_splits=2, random_state=1337, shuffle=True)\n",
    "    \n",
    "    for train_index, test_index in skf.split(df, labels):\n",
    "        #test_index, train_index = train_index, test_index \n",
    "        # get train and test set\n",
    "        X_train, X_test = df.take(train_index), df.take(test_index)\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        \n",
    "        # 1vRest training\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        print(\"Start fitting\")\n",
    "        lin_clf = svm.LinearSVC()\n",
    "        lin_clf.fit(X_train, y_train)\n",
    "        \n",
    "        # predicting\n",
    "        print(\"Start predicting\")\n",
    "        y_pred_lin_clf = lin_clf.predict(X_test)\n",
    "        \n",
    "        # metrics\n",
    "        #print(\"Calculating metrics\")\n",
    "        \n",
    "        print(f\"F1 macro-average: {metrics.f1_score(y_test, y_pred_lin_clf, average='macro')}\")\n",
    "        print(f\"F1 weighted-average: {metrics.f1_score(y_test, y_pred_lin_clf, average='weighted')}\")\n",
    "        f1 = metrics.f1_score(y_test, y_pred_lin_clf, average=None)\n",
    "        print(f\"accuracy: {metrics.accuracy_score(y_test, y_pred_lin_clf)}\")\n",
    "        \n",
    "        unique_labels_df = pd.DataFrame(pd.Series(y_test).unique())\n",
    "        f1_df = pd.DataFrame(f1)\n",
    "        print(pd.concat([unique_labels_df, f1_df], axis=1, keys=['dcluster', 'f1_per_dcluster']))\n",
    "        \n",
    "        # just do 1 iteration\n",
    "        return (lin_clf, f1)\n",
    "    \n",
    "    \n",
    "#drop_columns = filter(lambda col: col != \"Class\" , labels.columns)\n",
    "#list(drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec41e1e5-b7f1-4412-add6-167475fa18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_nn(df, labels, class_column_name): # todo: give linear classifier as argument\n",
    "    # only keep the needed column\n",
    "    drop_columns = filter(lambda col: col != class_column_name , labels.columns)\n",
    "    labels = labels.drop(columns = drop_columns).values.ravel()\n",
    "     \n",
    "    X_train, y_train = df, labels\n",
    "        \n",
    "    # 1vRest training\n",
    "    print(f\"Start training {class_column_name} entries with multiclass output: {pd.Series(y_train).unique()}\")\n",
    "    lin_clf = svm.LinearSVC()\n",
    "    lin_clf.fit(X_train, y_train)\n",
    "    \n",
    "    return lin_clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6529f652-65c1-42ff-95e3-b10ddc200369",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_linear_nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_linear_nn' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# as a test, train the first neural network to divide the data into Classes\n",
    "(clf, all_f1) = train_test_linear_nn(df, labels, \"Class\")\n",
    "all_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baad51bf-e405-4390-897d-4da0e9ba6ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tree structure\n",
    "class Node:\n",
    "    def __init__(self, parent, class_name):\n",
    "        self.parent = parent\n",
    "        self.class_name = class_name\n",
    "        \n",
    "        self.clf = None\n",
    "        self.children = dict() # dict die resultaat van clf linkt aan een nieuwe node (met clf)\n",
    "        \n",
    "    def __str__(self):\n",
    "        if self.parent is None:\n",
    "            return \"Root\"\n",
    "        return f\"(class_name: {self.class_name}, parent: {self.parent})\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d49ebd-7577-4bec-a649-13c6f7f42a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_on_class_name(df, labels, class_name, class_column_name):\n",
    "    keep_indices = labels[class_column_name] == class_name\n",
    "    return (df[keep_indices], labels[keep_indices])\n",
    "\n",
    "def train_hyr_nn(df, labels, node, parent_class=None, parent_class_column=None):\n",
    "    # train neural net to classify input in the child classes\n",
    "    \n",
    "    # get the child_class_column\n",
    "    if (parent_class is None or parent_class_column is None):\n",
    "        child_class_column = labels.columns[0]\n",
    "    else:\n",
    "        # make data smaller: remove all entries that do not belong to the parent_class\n",
    "        \n",
    "        df, labels = filter_data_on_class_name(df, labels, parent_class, parent_class_column)\n",
    "        \n",
    "        # get child_class_column\n",
    "        child_class_column_index = list(labels.columns).index(parent_class_column) + 1\n",
    "        if child_class_column_index >= len(labels.columns):\n",
    "            # we are at in a leaf of the hyr tree, there are no further child classes\n",
    "            return None\n",
    "        child_class_column = labels.columns[child_class_column_index]\n",
    "    \n",
    "    \n",
    "    # neural net that further classifies entries\n",
    "    unique_labels = pd.Series(labels[child_class_column]).unique()\n",
    "    if len(unique_labels) == 1:\n",
    "        # the subclass is the same as the parent class\n",
    "        node.clf = None\n",
    "    else:\n",
    "        print()\n",
    "        print(f\"parent_class: {parent_class}\")\n",
    "        node.clf = train_linear_nn(df, labels, child_class_column)\n",
    "    \n",
    "    # recursive step\n",
    "    for child_class in unique_labels: # todo: parallelize\n",
    "        child_node = Node(node, child_class)\n",
    "        train_hyr_nn(df, labels, child_node, child_class, child_class_column)\n",
    "        node.children[child_class] = child_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9bb861b3-613e-43f4-90bc-c1de08c91968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "\n",
      "parent_class: None\n",
      "Start training Class entries with multiclass output: ['GABAergic' 'Glutamatergic' 'Non-Neuronal']\n",
      "\n",
      "parent_class: GABAergic\n",
      "Start training Subclass entries with multiclass output: ['Lamp5' 'Sst' 'Vip' 'Sncg' 'Serpinf1' 'Pvalb']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parent_class: Lamp5\n",
      "Start training cluster entries with multiclass output: ['Lamp5 Lsp1' 'Lamp5 Krt73' 'Lamp5 Plch2 Dock5' 'Lamp5 Fam19a1 Tmem182'\n",
      " 'Lamp5 Ntn1 Npy2r' 'Lamp5 Lhx6' 'Lamp5 Fam19a1 Pax6']\n",
      "\n",
      "parent_class: Sst\n",
      "Start training cluster entries with multiclass output: ['Sst Tac1 Tacr3' 'Sst Chrna2 Glra3' 'Sst Hpse Sema3c' 'Sst Mme Fam114a1'\n",
      " 'Sst Nr2f2 Necab1' 'Sst Chodl' 'Sst Myh8 Etv1 ' 'Sst Myh8 Fibin'\n",
      " 'Sst Chrna2 Ptgdr' 'Sst Crh 4930553C11Rik ' 'Sst Calb2 Pdlim5'\n",
      " 'Sst Tac1 Htr1d' 'Sst Hpse Cbln4' 'Sst Crhr2 Efemp1' 'Sst Tac2 Tacstd2'\n",
      " 'Sst Rxfp1 Prdm8' 'Sst Rxfp1 Eya1' 'Sst Esm1' 'Sst Tac2 Myh4' 'Sst Nts'\n",
      " 'Sst Calb2 Necab1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parent_class: Vip\n",
      "Start training cluster entries with multiclass output: ['Vip Igfbp6 Car10' 'Vip Lect1 Oxtr' 'Vip Igfbp6 Pltp'\n",
      " 'Vip Crispld2 Kcne4' 'Vip Pygm C1ql1' 'Vip Ptprt Pkp2'\n",
      " 'Vip Arhgap36 Hmcn1' 'Vip Igfbp4 Mab21l1' 'Vip Crispld2 Htr2c'\n",
      " 'Vip Lmo1 Fam159b' 'Vip Chat Htr1f' 'Vip Lmo1 Myl1' 'Vip Gpc3 Slc18a3'\n",
      " 'Vip Rspo4 Rxfp1 Chat' 'Vip Rspo1 Itga4' 'Vip Col15a1 Pde1a']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parent_class: Sncg\n",
      "Start training cluster entries with multiclass output: ['Sncg Vip Itih5' 'Sncg Slc17a8' 'Sncg Vip Nptx2' 'Sncg Gpr50']\n",
      "\n",
      "parent_class: Serpinf1\n",
      "Start training cluster entries with multiclass output: ['Serpinf1 Aqp5 Vip' 'Serpinf1 Clrn1']\n",
      "\n",
      "parent_class: Pvalb\n",
      "Start training cluster entries with multiclass output: ['Pvalb Reln Tac1' 'Pvalb Tpbg' 'Pvalb Gpr149 Islr' 'Pvalb Th Sst'\n",
      " 'Pvalb Akr1c18 Ntf3' 'Pvalb Calb1 Sst' 'Pvalb Reln Itm2a' 'Pvalb Gabrg1'\n",
      " 'Pvalb Vipr2' 'Pvalb Sema3e Kank4']\n",
      "\n",
      "parent_class: Glutamatergic\n",
      "Start training Subclass entries with multiclass output: ['L6 CT' 'L6b' 'L6 IT' 'L2/3 IT' 'L5 PT' 'L4' 'NP' 'L5 IT']\n",
      "\n",
      "parent_class: L6 CT\n",
      "Start training cluster entries with multiclass output: ['L6 CT VISp Krt80 Sla' 'L6 CT VISp Ctxn3 Sla' 'L6 CT VISp Ctxn3 Brinp3'\n",
      " 'L6 CT VISp Gpr139' 'L6 CT VISp Nxph2 Wls' 'L6 CT ALM Nxph2 Sla']\n",
      "\n",
      "parent_class: L6b\n",
      "Start training cluster entries with multiclass output: ['L6b VISp Col8a1 Rprm' 'L6b VISp Mup5' 'L6b P2ry12'\n",
      " 'L6b VISp Col8a1 Rxfp1' 'L6b VISp Crh']\n",
      "\n",
      "parent_class: L6 IT\n",
      "Start training cluster entries with multiclass output: ['L6 IT VISp Col18a1' 'L6 IT VISp Col23a1 Adamts2'\n",
      " 'L6 IT VISp Penk Col27a1' 'L6 IT VISp Penk Fst' 'L6 IT VISp Car3']\n",
      "\n",
      "parent_class: L2/3 IT\n",
      "Start training cluster entries with multiclass output: ['L2/3 IT VISp Agmat' 'L2/3 IT VISp Rrad' 'L2/3 IT VISp Adamts2']\n",
      "\n",
      "parent_class: L5 PT\n",
      "Start training cluster entries with multiclass output: ['L5 PT VISp Krt80' 'L5 PT VISp Chrna6' 'L5 PT VISp C1ql2 Cdh13'\n",
      " 'L5 PT VISp C1ql2 Ptgfr' 'L5 PT VISp Lgr5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iwijn/ml/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parent_class: NP\n",
      "Start training cluster entries with multiclass output: ['L5 NP VISp Trhr Cpne7' 'L5 NP VISp Trhr Met']\n",
      "\n",
      "parent_class: L5 IT\n",
      "Start training cluster entries with multiclass output: ['L5 IT VISp Hsd11b1 Endou' 'L5 IT VISp Batf3' 'L5 IT VISp Col27a1'\n",
      " 'L5 IT VISp Col6a1 Fezf2' 'L5 IT VISp Whrn Tox2']\n",
      "SETTING TEST SET\n",
      "CPU times: user 3min 22s, sys: 31.1 s, total: 3min 53s\n",
      "Wall time: 3min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Root"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# get part of data where all cluster types are represented\n",
    "\n",
    "drop_columns = list(filter(lambda col: col != \"cluster\" , labels.columns))\n",
    "dclusters = labels.drop(columns = drop_columns).values.ravel()\n",
    "\n",
    "# only use part (1/5) of data for training and 1/5th for testing\n",
    "trained = False\n",
    "skf = StratifiedKFold(n_splits=2, random_state=1337, shuffle=True)\n",
    "for train_index, test_index in skf.split(df, dclusters):\n",
    "    if not trained:\n",
    "        print(\"TRAINING\")\n",
    "        root = Node(None, \"\")\n",
    "        train_hyr_nn(df.take(test_index), labels.take(test_index), root)\n",
    "        trained = True\n",
    "    else: \n",
    "        print(\"SETTING TEST SET\")\n",
    "        X_test_set = df.take(test_index)\n",
    "        y_test_set = labels.take(test_index)\n",
    "        break\n",
    "\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "853b921e-d217-4212-a40e-d7deda2a597c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(class_name: Astro Aqp4, parent: (class_name: Astro, parent: (class_name: Non-Neuronal, parent: Root)))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.children[\"Non-Neuronal\"].children[\"Astro\"].children[\"Astro Aqp4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6bad6929-d3fe-4384-8a5b-855efcbe4b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lamp5 Fam19a1 Pax6': (class_name: Lamp5 Fam19a1 Pax6, parent: (class_name: Lamp5, parent: (class_name: GABAergic, parent: Root))),\n",
      " 'Lamp5 Fam19a1 Tmem182': (class_name: Lamp5 Fam19a1 Tmem182, parent: (class_name: Lamp5, parent: (class_name: GABAergic, parent: Root))),\n",
      " 'Lamp5 Krt73': (class_name: Lamp5 Krt73, parent: (class_name: Lamp5, parent: (class_name: GABAergic, parent: Root))),\n",
      " 'Lamp5 Lhx6': (class_name: Lamp5 Lhx6, parent: (class_name: Lamp5, parent: (class_name: GABAergic, parent: Root))),\n",
      " 'Lamp5 Lsp1': (class_name: Lamp5 Lsp1, parent: (class_name: Lamp5, parent: (class_name: GABAergic, parent: Root))),\n",
      " 'Lamp5 Ntn1 Npy2r': (class_name: Lamp5 Ntn1 Npy2r, parent: (class_name: Lamp5, parent: (class_name: GABAergic, parent: Root))),\n",
      " 'Lamp5 Plch2 Dock5': (class_name: Lamp5 Plch2 Dock5, parent: (class_name: Lamp5, parent: (class_name: GABAergic, parent: Root)))}\n",
      "LinearSVC()\n"
     ]
    }
   ],
   "source": [
    "# pprint(root.children)\n",
    "# pprint(root.children[\"GABAergic\"].children)\n",
    "pprint(root.children[\"GABAergic\"].children[\"Lamp5\"].children)\n",
    "pprint(root.children[\"GABAergic\"].children[\"Lamp5\"].clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a4a60ba-fc96-4f9a-b3eb-bb19b429b2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0\n",
      "7          GABAergic\n",
      "10         GABAergic\n",
      "12         GABAergic\n",
      "16         GABAergic\n",
      "18         GABAergic\n",
      "...              ...\n",
      "12818  Glutamatergic\n",
      "12819      GABAergic\n",
      "12820      GABAergic\n",
      "12824  Glutamatergic\n",
      "12825  Glutamatergic\n",
      "\n",
      "[2556 rows x 1 columns]\n",
      "           0\n",
      "7      Lamp5\n",
      "10       Vip\n",
      "12       Vip\n",
      "16     Lamp5\n",
      "18     Lamp5\n",
      "...      ...\n",
      "12799    Sst\n",
      "12803    Sst\n",
      "12810  Pvalb\n",
      "12819    Sst\n",
      "12820    Sst\n",
      "\n",
      "[1129 rows x 1 columns]\n",
      "                       0\n",
      "7            Lamp5 Krt73\n",
      "16            Lamp5 Lsp1\n",
      "18            Lamp5 Lsp1\n",
      "38      Lamp5 Ntn1 Npy2r\n",
      "56            Lamp5 Lsp1\n",
      "...                  ...\n",
      "12471   Lamp5 Ntn1 Npy2r\n",
      "12472   Lamp5 Ntn1 Npy2r\n",
      "12475         Lamp5 Lsp1\n",
      "12491  Lamp5 Plch2 Dock5\n",
      "12495  Lamp5 Plch2 Dock5\n",
      "\n",
      "[218 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# This is how 1 branch of the hyr tree, all the way down, should be trained\n",
    "\n",
    "# Train on the whole dataset to divide in Class\n",
    "l1_res_df = pd.DataFrame(root.clf.predict(X_test_set))\n",
    "l1_res_df.index = X_test_set.index # set the same indexes before further filtering\n",
    "pprint(l1_res_df) # aha! this keeps the old indices\n",
    "\n",
    "# filter out all entries that gave Class \"GABAergic\" and train on this subset to determine Subclass\n",
    "l2_input = X_test_set[l1_res_df[0] == \"GABAergic\"]\n",
    "l2_res_df = pd.DataFrame(root.children[\"GABAergic\"].clf.predict(l2_input))\n",
    "l2_res_df.index = l2_input.index\n",
    "pprint(l2_res_df) # aha! this keeps the old indices\n",
    "\n",
    "# filter out all entries that gave Subclass \"Lamp5\" and finally train on cluster\n",
    "l3_input = l2_input[l2_res_df[0] == \"Lamp5\"]\n",
    "l3_res_df = pd.DataFrame(root.children[\"GABAergic\"].children[\"Lamp5\"].clf.predict(l3_input))\n",
    "l3_res_df.index = l3_input.index\n",
    "pprint(l3_res_df) # aha! this keeps the old indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d914aa9d-3463-4748-ae16-e8b6290df727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0\n",
      "7          GABAergic\n",
      "10         GABAergic\n",
      "12         GABAergic\n",
      "16         GABAergic\n",
      "18         GABAergic\n",
      "...              ...\n",
      "12818  Glutamatergic\n",
      "12819      GABAergic\n",
      "12820      GABAergic\n",
      "12824  Glutamatergic\n",
      "12825  Glutamatergic\n",
      "\n",
      "[2556 rows x 1 columns]\n",
      "           0\n",
      "113    L6 CT\n",
      "118    L6 CT\n",
      "119    L6 CT\n",
      "124    L6 CT\n",
      "126    L6 CT\n",
      "...      ...\n",
      "12800  L6 IT\n",
      "12809  L6 IT\n",
      "12818  L5 PT\n",
      "12824  L5 PT\n",
      "12825  L5 PT\n",
      "\n",
      "[1426 rows x 1 columns]\n",
      "                      0\n",
      "480    L4 IT VISp Rspo1\n",
      "484    L4 IT VISp Rspo1\n",
      "486    L4 IT VISp Rspo1\n",
      "489    L4 IT VISp Rspo1\n",
      "491    L4 IT VISp Rspo1\n",
      "...                 ...\n",
      "11218  L4 IT VISp Rspo1\n",
      "11220  L4 IT VISp Rspo1\n",
      "11245  L4 IT VISp Rspo1\n",
      "12447  L4 IT VISp Rspo1\n",
      "12448  L4 IT VISp Rspo1\n",
      "\n",
      "[267 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Train on the whole dataset to divide in Class\n",
    "l1_res_df = pd.DataFrame(root.clf.predict(X_test_set))\n",
    "l1_res_df.index = X_test_set.index # set the same indexes before further filtering\n",
    "pprint(l1_res_df) # aha! this keeps the old indices\n",
    "\n",
    "# filter out all entries that gave Class \"GABAergic\" and train on this subset to determine Subclass\n",
    "l2_input = X_test_set[l1_res_df[0] == \"Glutamatergic\"]\n",
    "l2_res_df = pd.DataFrame(root.children[\"Glutamatergic\"].clf.predict(l2_input))\n",
    "l2_res_df.index = l2_input.index\n",
    "pprint(l2_res_df) # aha! this keeps the old indices\n",
    "\n",
    "# Special case: everything in L4 class belongs to the same cluster (so no further predicting has to / can be done)\n",
    "# filter out all entries that gave Subclass \"Lamp5\" and finally train on cluster\n",
    "l3_input = l2_input[l2_res_df[0] == \"L4\"]\n",
    "# instead of further classifying:\n",
    "#l3_res_df = pd.DataFrame(root.children[\"Glutamatergic\"].children[\"L4\"].clf.predict(l3_input)) # clf is None\n",
    "#l3_res_df.index = l3_input.index\n",
    "# we set the result to the the more specific cluster name of the one and only child\n",
    "l3_res_df = pd.DataFrame(index=l3_input.index, columns=[0]).fillna(root.children[\"Glutamatergic\"].children[\"L4\"].children[\"L4 IT VISp Rspo1\"].class_name)\n",
    "\n",
    "pprint(l3_res_df) # aha! this keeps the old indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49aeeda-0fdb-4f6a-8f2e-4db5158636d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0619a9e4-705b-42ec-ad8d-e85bc8c83a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the hyr nn tree and an input, predict the cluster\n",
    "\n",
    "# recursive\n",
    "def predict(node, X_test):\n",
    "    #### Printing\n",
    "    spaces = 1\n",
    "    it_node = node\n",
    "    while it_node.parent is not None:\n",
    "        it_node = it_node.parent\n",
    "        spaces += 2\n",
    "    print((spaces*\"--\") + f\"{node.class_name if node.parent is not None else 'Root' }\")\n",
    "    ####\n",
    "    \n",
    "    # the tree goes further down, but there is only 1 subclass and thus no further classifier needs to be executed\n",
    "    if node.clf is None:\n",
    "        child_node = list(node.children.values())[0]\n",
    "        y_test = pd.DataFrame(index=X_test.index, columns=[0]).fillna(child_node.class_name) \n",
    "        #print(child_node.class_name)\n",
    "    else:\n",
    "        y_test = pd.DataFrame(node.clf.predict(X_test))\n",
    "        y_test.index = X_test.index # keep original indices\n",
    "    \n",
    "    # we are in a leaf when the children dont have any children themselves\n",
    "    # (We dont need to call predict on a child if they wont be able to futher classify to their children\n",
    "    if list(node.children.values())[0].children == {}:\n",
    "        return y_test\n",
    "    else:\n",
    "        # the children do have a clf to further classify, so further classify\n",
    "        predictions = []\n",
    "        for label, child_node in node.children.items():\n",
    "            new_X_test = X_test[y_test[0] == label]\n",
    "            predictions.append(predict(child_node, new_X_test))\n",
    "        return pd.concat(predictions)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "11a382b1-c619-4524-abcf-fcd16984d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Root\n",
      "------GABAergic\n",
      "----------Lamp5\n",
      "----------Sst\n",
      "----------Vip\n",
      "----------Sncg\n",
      "----------Serpinf1\n",
      "----------Pvalb\n",
      "------Glutamatergic\n",
      "----------L6 CT\n",
      "----------L6b\n",
      "----------L6 IT\n",
      "----------L2/3 IT\n",
      "----------L5 PT\n",
      "----------L4\n",
      "----------NP\n",
      "----------L5 IT\n",
      "------Non-Neuronal\n",
      "----------Astro\n",
      "CPU times: user 22.8 s, sys: 40.3 s, total: 1min 3s\n",
      "Wall time: 41.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y_pred_hyr = predict(root, X_test_set).sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b195635b-be37-400d-91a5-ecdb07fee3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_hyr.loc[pd.isna(y_pred_hyr[0]), :].index\n",
    "# y_test_set.loc[pd.isna(y_test_set[\"cluster\"]), :].index\n",
    "print(pd.isna(y_test_set[\"cluster\"]).any())\n",
    "pd.isna(y_pred_hyr[0]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4b9c166b-4638-4b75-814b-4936c5c7e129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7        False\n",
      "10       False\n",
      "12       False\n",
      "16       False\n",
      "18       False\n",
      "         ...  \n",
      "12818    False\n",
      "12819    False\n",
      "12820    False\n",
      "12824    False\n",
      "12825    False\n",
      "Name: cluster, Length: 2556, dtype: bool\n",
      "7        False\n",
      "10       False\n",
      "12       False\n",
      "16       False\n",
      "18       False\n",
      "         ...  \n",
      "12818    False\n",
      "12819    False\n",
      "12820    False\n",
      "12824    False\n",
      "12825    False\n",
      "Name: 0, Length: 2556, dtype: bool\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "test_set_bools = y_test_set[\"cluster\"] == \"Astro Aqp4\"\n",
    "pred_bools = y_pred_hyr[0] == \"Astro Aqp4\"\n",
    "\n",
    "pprint(test_set_bools)\n",
    "pprint(pred_bools)\n",
    "\n",
    "print(test_set_bools.any())\n",
    "print(pred_bools.any()) # no predictions of Astro Aqp4 were found! this explains why F1 is 0\n",
    "                        # seems like they are all called \"Astro\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ad825373-f97a-4542-b03e-ca7f1cbe9f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Vip Arhgap36 Hmcn1\n",
      "3        Vip Crispld2 Htr2c\n",
      "4         Lamp5 Plch2 Dock5\n",
      "6            Sncg Vip Itih5\n",
      "11       Vip Crispld2 Kcne4\n",
      "                ...        \n",
      "12826       Sst Hpse Sema3c\n",
      "12827     L5 PT VISp Chrna6\n",
      "12828            Sncg Gpr50\n",
      "12829     Pvalb Gpr149 Islr\n",
      "12831      Sst Calb2 Pdlim5\n",
      "Name: cluster, Length: 6390, dtype: object\n",
      "0        Vip Arhgap36 Hmcn1\n",
      "3        Vip Crispld2 Htr2c\n",
      "4         Lamp5 Plch2 Dock5\n",
      "6            Sncg Vip Itih5\n",
      "11       Vip Crispld2 Kcne4\n",
      "                ...        \n",
      "12826       Sst Hpse Sema3c\n",
      "12827     L5 PT VISp Chrna6\n",
      "12828            Sncg Gpr50\n",
      "12829     Pvalb Gpr149 Islr\n",
      "12831      Sst Calb2 Pdlim5\n",
      "Name: 0, Length: 6390, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pprint(y_test_set[\"cluster\"])\n",
    "pprint(y_pred_hyr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b1ba8b65-5c21-4350-82c4-2d66a029d164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dcluster f1_per_dcluster\n",
      "                     0               0\n",
      "0   Vip Arhgap36 Hmcn1        0.835165\n",
      "1   Vip Crispld2 Htr2c        0.837209\n",
      "2    Lamp5 Plch2 Dock5        0.884354\n",
      "3       Sncg Vip Itih5        0.823529\n",
      "4   Vip Crispld2 Kcne4        0.884615\n",
      "..                 ...             ...\n",
      "88     L5 PT VISp Lgr5        0.736842\n",
      "89    Sst Calb2 Necab1        0.315789\n",
      "90          L6b P2ry12        0.941176\n",
      "91       L6b VISp Mup5        0.981818\n",
      "92        L6b VISp Crh        0.923077\n",
      "\n",
      "[93 rows x 2 columns]\n",
      "acc: 0.9020344287949922\n",
      "\n",
      "F1 micro-average: 0.9020344287949922\n",
      "F1 macro-average: 0.8420932014001663\n",
      "F1 weighted-average: 0.9003196202455704\n"
     ]
    }
   ],
   "source": [
    "f1 = metrics.f1_score(y_test_set[\"cluster\"], y_pred_hyr[0], average=None, labels = unique_labels_df[0])\n",
    "acc = metrics.accuracy_score(y_test_set[\"cluster\"], y_pred_hyr[0])\n",
    "\n",
    "unique_labels_df = pd.DataFrame(pd.Series(y_test_set[\"cluster\"]).unique())\n",
    "\n",
    "f1_df = pd.DataFrame(f1)\n",
    "f1_df_labeled = pd.concat([unique_labels_df, f1_df], axis=1, keys=['dcluster', 'f1_per_dcluster'])\n",
    "print(f1_df_labeled)\n",
    "print(f\"acc: {acc}\")\n",
    "print()\n",
    "print(f\"F1 micro-average: {metrics.f1_score(y_test_set['cluster'], y_pred_hyr[0], average='micro')}\")\n",
    "print(f\"F1 macro-average: {metrics.f1_score(y_test_set['cluster'], y_pred_hyr[0], average='macro')}\")\n",
    "print(f\"F1 weighted-average: {metrics.f1_score(y_test_set['cluster'], y_pred_hyr[0], average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "37d9c3f4-40bd-4b77-8494-1045bfc2f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export f1 scores (file in results/ folder)\n",
    "f1_df_labeled.to_csv(\"all_f1_scores_hyr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4512c81f-051d-4077-a58d-2f1a7d5b106e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40375da2-b5d0-4963-a89e-285981137b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
